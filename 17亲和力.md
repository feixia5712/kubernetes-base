## **Affinity**

### 简介

```
pod的亲和力主要用来解决如下几个问题主要涉及pod跟节点以及pod跟pod的问题
01 某些Pod优先选择有ssd=true标签的节点，如果没有在考虑部署到其它节点；
02 某些Pod需要部署在ssd=true和type=physical的节点上，但是优先部署在ssd=true的节点上；
03 同一个应用的Pod不同的副本或者同一个项目的应用尽量或必须不部署在同一个节点或者符合某个标签的一类节点上或者不同的区域；
04 相互依赖的两个Pod尽量或必须部署在同一个节点上或者同一个域内。
```

### 分类

```
Affinity亲和力：
	NodeAffinity：节点亲和力
	PodAffinity：Pod亲和力
	PodAntiAffinity：Pod反亲和力
```

现在是3个

```
requiredDuringSchedulingIgnoredDuringExecution 　　　　　　必须满足，标签变化时不处理(是硬限制，必须满足此条件才可以调度pod到该node上)

requiredDuringSchedulingRequiredDuringExecution　　　　　  必须满足，标签变化时重新选择（暂未支持）

preferredDuringSchedulingIgnoredDuringExecution　　　　　　优先满足，标签变化时不处理 （是软限制，强调优先满足制定规则，多个优先级可以设置权重）
```



![image-20210921213304947](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210921213304947.png)

### 节点亲和力nodeAffinity

```
apiVersion: v1
kind: Pod
metadata:
  name: with-node-affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/e2e-az-name
            operator: In
            values:
            - e2e-az1
            - az-2
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: another-node-label-key
            operator: In
            values:
            - another-node-label-value
  containers:
  - name: with-node-affinity
    image: nginx
```

说明如下

```
该规则要求将pod放置在节点上，且节点的标签的关键字是e2e-az-name，其值是e2e-az1或者az-2
requiredDuringSchedulingIgnoredDuringExecution：硬亲和力配置
nodeSelectorTerms：节点选择器配置，可以配置多个matchExpressions（满足其一），每个matchExpressions下可以配置多个key、value类型的选择器（都需要满足），其中values可以配置多个（满足其一）
preferredDuringSchedulingIgnoredDuringExecution：软亲和力配置
weight：软亲和力的权重，权重越高优先级越大，范围1-100
preference：软亲和力配置项，和weight同级，可以配置多个，matchExpressions和硬亲和力一致
operator：标签匹配的方式
In：相当于key = value的形式
NotIn：相当于key != value的形式
Exists：节点存在label的key为指定的值即可，不能配置values字段
DoesNotExist：节点不存在label的key为指定的值即可，不能配置values字段
Gt：大于value指定的值
Lt：小于value指定的值
```
Node Afffinity  总结
如果设置了nodeSelector和nodeAffinity，则需同时满足。
如果设置多个nodeSelectorTerms，有一个满足即可。
如果nodeSelectorTerms下有多个 matchExpressions，则必须满足所有条件才可以。


### Pod亲和力和反亲和力讲解

官网地址:https://kubernetes.io/zh/docs/concepts/scheduling-eviction/assign-pod-node/

```
apiVersion: v1
kind: Pod
metadata:
  name: with-pod-affinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: security
            operator: In
            values:
            - S1
        topologyKey: failure-domain.beta.kubernetes.io/zone
        #pod必须部署在一个节点上，这个节点上至少有一个正在运行的pod，这个pod中security=S1
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: security
              operator: In
              values:
              - S2
          namespaces:
          - default
          topologyKey: failure-domain.beta.kubernetes.io/zone
          #pod不太会部署在一个节点上，（什么样的节点）这个节点上正在运行的pod中有security=S2，所以当一个node节点有pod的标签是security=S2，则在部署这个的时候就不会部署到这个节点，这样这两个pod就不会在同一个节点上
  containers:
  - name: with-pod-affinity
    image: nginx
```

说明

```
labelSelector：Pod选择器配置，可以配置多个
matchExpressions：和节点亲和力配置一致	
operator：配置和节点亲和力一致，但是没有Gt和Lt
topologyKey：匹配的拓扑域的key，也就是节点上label的key，key和value相同的为同一个域，可以用于标注不同的机房和地区，topologyKey kubernetes.io/hostname 表示这个域是一个单独的节点
Namespaces: 和哪个命名空间的Pod进行匹配，为空为当前命名空间
```

### 案例

同一个应用部署在不同的宿主机

```
[root@k8s-master01 NodeAffinaty]# cat nodeaffi01.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: must-be-diff-nodes
  name: must-be-diff-nodes
  namespace: kube-public
spec:
  replicas: 3
  selector:
    matchLabels:
      app: must-be-diff-nodes
  template:
    metadata:
      labels:
        app: must-be-diff-nodes
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - must-be-diff-nodes
            topologyKey: kubernetes.io/hostname
      containers:
      - image: nginx
        imagePullPolicy: IfNotPresent
        name: must-be-diff-nodes
```

说明

```

labelSelector：Pod选择器配置，可以配置多个
matchExpressions：和节点亲和力配置一致	
operator：配置和节点亲和力一致，但是没有Gt和Lt
topologyKey：匹配的拓扑域的key，也就是节点上label的key，key和value相同的为同一个域，一个域里面只能部署一个pod,可以用于标注不同的机房和地区，此处为 kubernetes.io/hostname标识每台机器为一个域

此处是pod反亲和力,部署nginx，pod不会部署在一个节点上，（什么样的节点）这个节点上正在运行的pod中有security=S2，所以当一个node节点有pod的标签是security=S2，则在部署pod的时候就不会部署到这个节点，这样deploy的pod就不会在同一个节点上

[root@k8s-master01 NodeAffinaty]# kubectl get pod -n kube-public -owide
NAME                                  READY   STATUS    RESTARTS   AGE     IP               NODE           NOMINATED NODE   READINESS GATES
must-be-diff-nodes-676bfbcd4c-cwc2s   1/1     Running   0          22h     172.27.14.200    k8s-node02     <none>           <none>
must-be-diff-nodes-676bfbcd4c-g5wcf   1/1     Running   0          22h     172.25.244.251   k8s-master01   <none>           <none>
must-be-diff-nodes-676bfbcd4c-xgj2z   1/1     Running   0          22h     172.25.92.77     k8s-master02   <none>           <none>

```

同一个应用不同副本固定节点

```
[root@k8s-master01 NodeAffinaty]# cat nodeaffi02.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-cache
  namespace: kube-public
spec:
  selector:
    matchLabels:
      app: store
  replicas: 3
  template:
    metadata:
      labels:
        app: store
    spec:
      nodeSelector:
          app: store
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - store
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: redis-server
        image: redis:3.2-alpine
```

说明：

```
redis-server只会部署在打标签为app=store的机器上
```

应用和缓存尽量部署在同一个域内（topologyKey保持一致）

先部署中间件

```
[root@k8s-master01 NodeAffinaty]# cat nodeaffi02.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-cache
  namespace: kube-public
spec:
  selector:
    matchLabels:
      app: store
  replicas: 3
  template:
    metadata:
      labels:
        app: store
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - store01
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: redis-server
        image: redis:3.2-alpine
```

注意app=store标签，下边的应用会使用到

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-server
  namespace: kube-public
spec:
  selector:
    matchLabels:
      app: web-store
  replicas: 3
  template:
    metadata:
      labels:
        app: web-store
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - web-store
            topologyKey: "kubernetes.io/hostname"
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - store
              topologyKey: "kubernetes.io/hostname"
              #优先选择有pod标签为app=store的机器上，正好会选择到redis这个中间件的机器
      containers:
      - name: web-app
        image: nginx:1.16-alpine
```

说明

```
以上两个affinity，匹配到一个即可，中间件应用使用app=store即可，就会部署到一台机器上
podAntiAffinity的app=store保证deploy在3台机器上,podAffinity用来关联中间件服务，保证部署的服务跟中间件在同一台机器上
```

查看

```
[root@k8s-master01 NodeAffinaty]# kubectl get pod -n kube-public -owide
NAME                           READY   STATUS    RESTARTS   AGE     IP               NODE           NOMINATED NODE   READINESS GATES
redis-cache-74c498f974-528m6   1/1     Running   0          6m20s   172.27.14.216    k8s-node02     <none>           <none>
redis-cache-74c498f974-gq44j   1/1     Running   0          6m20s   172.25.244.195   k8s-master01   <none>           <none>
redis-cache-74c498f974-ssfv8   1/1     Running   0          6m20s   172.25.92.87     k8s-master02   <none>           <none>
web-server-d66c7b4fd-h454v     1/1     Running   0          5m34s   172.25.92.89     k8s-master02   <none>           <none>
web-server-d66c7b4fd-splbb     1/1     Running   0          5m34s   172.25.244.196   k8s-master01   <none>           <none>
web-server-d66c7b4fd-z754c     1/1     Running   0          5m34s   172.27.14.218    k8s-node02     <none>           <none>
```

### 拓扑域TopologyKey详解

参考https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-topology-spread-constraints/

```
你可以使用 拓扑分布约束（Topology Spread Constraints） 来控制 Pods 在集群内故障域 之间的分布，例如区域（Region）、可用区（Zone）、节点和其他用户自定义拓扑域。 这样做有助于实现高可用并提升资源利用率。
```

例如如下

```
topologyKey: zone
节点内容如下
NAME    STATUS   ROLES    AGE     VERSION   LABELS
node1   Ready    <none>   4m26s   v1.16.0   node=node1,zone=zoneA
node2   Ready    <none>   3m58s   v1.16.0   node=node2,zone=zoneA
node3   Ready    <none>   3m17s   v1.16.0   node=node3,zone=zoneB
node4   Ready    <none>   2m43s   v1.16.0   node=node4,zone=zoneB

相当于一个zone包含两个node节点
zoneA包含node1 node2
zoneB包含node3 node4
当部署应用的时候一个副本会落在node1或者node2其中一个节点上,另外的副本会落在node3或者node4其中一个上
```

案例

```
当前所有node节点不存在region标签的情况下,我们使用的是亲和力
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: must-be-diff-zone
  name: must-be-diff-zone
  namespace: kube-public
spec:
  replicas: 3
  selector:
    matchLabels:
      app: must-be-diff-zone
  template:
    metadata:
      labels:
        app: must-be-diff-zone
    spec:
      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - must-be-diff-zone
            topologyKey: region
      containers:
      - image: nginx
        imagePullPolicy: IfNotPresent
        name: must-be-diff-zone
当创建的时候，由于没有给节点加上标签region，会造成创建的所有副本pending
[root@k8s-master01 tokey]# kubectl get pod -n kube-public
NAME                                 READY   STATUS    RESTARTS   AGE
must-be-diff-zone-6b888645b4-9jgrr   0/1     Pending   0          5s
must-be-diff-zone-6b888645b4-n4j95   0/1     Pending   0          5s
must-be-diff-zone-6b888645b4-vc28c   0/1     Pending   0          5s
但是如果是podAntiAffinity反亲和力的话,根据官网说明，就会造成意想不到的情况，可能pod会正常运行
Pod 反亲和性需要对节点进行一致的标记，即集群中的每个节点必须具有适当的标签能够匹配 topologyKey。如果某些或所有节点缺少指定的 topologyKey 标签，可能会导致意外行为。
说明:https://kubernetes.io/zh/docs/concepts/scheduling-eviction/assign-pod-node/
```

案例02

```
kubectl label node k8s-master03 region=vv
kubectl label node k8s-master01 k8s-master02 region=daxing
kubectl label node k8s-node01 k8s-node02 region=cangping
[root@k8s-master01 tokey]# cat tokey.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: must-be-diff-zone
  name: must-be-diff-zone
  namespace: kube-public
spec:
  replicas: 4
  selector:
    matchLabels:
      app: must-be-diff-zone
  template:
    metadata:
      labels:
        app: must-be-diff-zone
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - must-be-diff-zone
            topologyKey: region
      containers:
      - image: nginx
        imagePullPolicy: IfNotPresent
        name: must-be-diff-zone
```

创建后发现有一个会一直pending,原因是region不够分配了

```
[root@k8s-master01 tokey]# kubectl get pod -n kube-public -owide
NAME                                READY   STATUS    RESTARTS   AGE     IP              NODE           NOMINATED NODE   READINESS GATES
must-be-diff-zone-9bdbb4d88-bpvzv   1/1     Running   0          2m46s   172.25.92.98    k8s-master02   <none>           <none>
must-be-diff-zone-9bdbb4d88-dj2wx   0/1     Pending   0          2m46s   <none>          <none>         <none>           <none>
must-be-diff-zone-9bdbb4d88-hjz9q   1/1     Running   0          2m46s   172.27.14.225   k8s-node02     <none>           <none>
must-be-diff-zone-9bdbb4d88-t6qr9   1/1     Running   0          2m46s   172.18.195.23   k8s-master03   <none>           <none>

```

