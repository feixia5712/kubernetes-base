## 准入控制资源配额

### Qos服务质量

```
Guaranteed：最高服务质量，当宿主机内存不够时，会先kill掉QoS为BestEffort和Burstable的Pod，如果内存还是不够，才会kill掉QoS为Guaranteed，该级别Pod的资源占用量一般比较明确，即requests的cpu和memory和limits的cpu和memory配置的一致。

Burstable： 服务质量低于Guaranteed，当宿主机内存不够时，会先kill掉QoS为BestEffort的Pod，如果内存还是不够之后就会kill掉QoS级别为Burstable的Pod，用来保证QoS质量为Guaranteed的Pod，该级别Pod一般知道最小资源使用量，但是当机器资源充足时，还是想尽可能的使用更多的资源，即limits字段的cpu和memory大于requests的cpu和memory的配置。

BestEffort：尽力而为，当宿主机内存不够时，首先kill的就是该QoS的Pod，用以保证Burstable和Guaranteed级别的Pod正常运行。

```

#### 实现QoS为Guaranteed的Pod

```
kubectl create ns qos-example
[root@k8s-master01 qos]# cat g.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: qos-demo
  namespace: qos-example
spec:
  containers:
  - name: qos-demo-ctr
    image: nginx
    resources:
      limits:
        cpu: 1
        memory: "200Mi"
      requests:
        cpu: 1
        memory: "200Mi"     
```

创建查看

```
[root@k8s-master01 qos]# cat g.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: qos-demo
  namespace: qos-example
spec:
  containers:
  - name: qos-demo-ctr
    image: nginx
    resources:
      limits:
        cpu: 1
        memory: "200Mi"
      requests:
        cpu: 1
        memory: "200Mi"
[root@k8s-master01 qos]# kubectl create -f g.yaml 
pod/qos-demo created
[root@k8s-master01 qos]# kubectl get -f g.yaml -oyaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2021-10-19T13:44:40Z"
  name: qos-demo
  namespace: qos-example
  resourceVersion: "9405963"
  uid: 40bd4928-672b-47e8-b761-0cad9be8a8c1
spec:
  containers:
  - image: nginx
    imagePullPolicy: Always
    name: qos-demo-ctr
    resources:
      limits:
        cpu: "1"    #保持limit跟request资源一样
        memory: 200Mi
      requests:
        cpu: "1"
        memory: 200Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-fr5kq
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  nodeName: k8s-node02
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: kube-api-access-fr5kq
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:44:40Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:44:58Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:44:58Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:44:40Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: docker://10cb601f5ba6c79adec611c0d4e60e44b2c74d2aa62a44a6ef06745c28a0b3f1
    image: nginx:latest
    imageID: docker-pullable://nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36
    lastState: {}
    name: qos-demo-ctr
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2021-10-19T13:44:58Z"
  hostIP: 192.168.10.184
  phase: Running
  podIP: 172.27.14.229
  podIPs:
  - ip: 172.27.14.229
  qosClass: Guaranteed      #qos为最高服务质量
  startTime: "2021-10-19T13:44:40Z"
  
  
Pod中的每个容器必须指定limits.memory和requests.memory，并且两者需要相等；
Pod中的每个容器必须指定limits.cpu和limits.memory，并且两者需要相等。

```

#### QoS为Burstable的Pod

```
[root@k8s-master01 qos]# cat b.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: qos-demo-2
  namespace: qos-example
spec:
  containers:
  - name: qos-demo-2-ctr
    image: nginx
    resources:
      limits:
        memory: "200Mi"
      requests:
        memory: "100Mi"
[root@k8s-master01 qos]# kubectl create -f b.yaml 
pod/qos-demo-2 created
[root@k8s-master01 qos]# kubectl get -f b.yaml -oyaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2021-10-19T13:48:00Z"
  name: qos-demo-2
  namespace: qos-example
  resourceVersion: "9406411"
  uid: a154fb85-8b34-412c-8498-0a9dd3b4c5e5
spec:
  containers:
  - image: nginx
    imagePullPolicy: Always
    name: qos-demo-2-ctr
    resources:
      limits:
        memory: 200Mi
      requests:
        memory: 100Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-g278g
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  nodeName: k8s-master01
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: kube-api-access-g278g
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:48:00Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:48:00Z"
    message: 'containers with unready status: [qos-demo-2-ctr]'
    reason: ContainersNotReady
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:48:00Z"
    message: 'containers with unready status: [qos-demo-2-ctr]'
    reason: ContainersNotReady
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:48:00Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - image: nginx
    imageID: ""
    lastState: {}
    name: qos-demo-2-ctr
    ready: false
    restartCount: 0
    started: false
    state:
      waiting:
        reason: ContainerCreating
  hostIP: 192.168.10.180
  phase: Pending
  qosClass: Burstable    #qos值
  startTime: "2021-10-19T13:48:00Z"

```

```
Pod不符合Guaranteed的配置要求；
Pod中至少有一个容器配置了requests.cpu或requests.memory。
```

#### QoS为BestEffort的Pod

```
apiVersion: v1
kind: Pod
metadata:
  name: qos-demo-3
  namespace: qos-example
spec:
  containers:
  - name: qos-demo-3-ctr
    image: nginx
    
不设置resources参数
```

演示如下

```
[root@k8s-master01 qos]# kubectl create -f c.yaml 
pod/qos-demo-3 created
[root@k8s-master01 qos]# kubectl get -f c.yaml -oyaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2021-10-19T13:52:02Z"
  name: qos-demo-3
  namespace: qos-example
  resourceVersion: "9407015"
  uid: 00ab59e3-fc5d-4800-8dc2-6555fbcda6f2
spec:
  containers:
  - image: nginx
    imagePullPolicy: Always
    name: qos-demo-3-ctr
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-p6t8m
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  nodeName: k8s-master01
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: kube-api-access-p6t8m
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:52:02Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:52:02Z"
    message: 'containers with unready status: [qos-demo-3-ctr]'
    reason: ContainersNotReady
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:52:02Z"
    message: 'containers with unready status: [qos-demo-3-ctr]'
    reason: ContainersNotReady
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2021-10-19T13:52:02Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - image: nginx
    imageID: ""
    lastState: {}
    name: qos-demo-3-ctr
    ready: false
    restartCount: 0
    started: false
    state:
      waiting:
        reason: ContainerCreating
  hostIP: 192.168.10.180
  phase: Pending
  qosClass: BestEffort
  startTime: "2021-10-19T13:52:02Z"
```

参考Kubernetes 的 Limit 和 Request:https://zhuanlan.zhihu.com/p/114765307